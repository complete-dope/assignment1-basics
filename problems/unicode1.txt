Q. What does chr(0) mean ? 
> \x00 , these are control characters that are non printable, its is a null character

Q. How does this characters string representation differ from its printed representation ? 
> repr(chr(0)) : this outputs \x00 , null character ( hexadecimal escape for value 0)
> print(repr(chr(0))) : prints nothing 

Unicode Standard defines a mapping from characters to code points, since vocab would be large (around 150K items) and sparse (since many characters are quite rare) 

Unicode Encoding converts a unicode character into a sequence of bytes

Unicode codepoints into a sequence of bytes (e.g., via the UTF-8 encoding), we are essentially taking a sequence of codepoints (integers in the range 0 to 154,997) and transforming it into a sequence of byte values (integers in the range 0 to 255)

So each character is encoded within range of 0-255 but can take multiple bits .. 
How to know what is a leading bit and what is a continuation byte ? 
leading bit always start with '1' , so a 2 byte representation would be something like : 110xxxxx , a 3 byte representation would be something like : 1110xxxx , a 4 byte representation would be something like 11110xxx

so ß which is C3 9F in utf-8 has representation as : `11000011 10011111`

```bash
C3 = 11000011 → leading byte for 2-byte sequence  
9F = 10011111 → continuation byte must start with '1'
```


Q. What are some reasons to prefer training our tokenizer on UTF-8 encoded bytes, rather than
UTF-16 or UTF-32? It may be helpful to compare the output of these encodings for various
input strings.
> UTF-16 each character is encoded using 2 bytes (16 bits) , and 


This is byte level tokenization, the problem is longer input sequences create long-term dependencies in the data.


Section 2.3 to be continued !!